{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "%load_ext sql\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import glob\n",
    "import sqlite3\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "sys.path.append(\"/home/czw/.local/lib/python3.6/site-packages/\")\n",
    "from astrowidgets import ImageWidget\n",
    "import ipywidgets as widgets\n",
    "import astropy.io.fits as FF\n",
    "from astropy.table import QTable, hstack\n",
    "import astropy.units as u\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import lsst.afw.image as afwImage\n",
    "import lsst.daf.persistence as dafPersist\n",
    "PROJ_DIR = '/project/czw/rc2_comp.20200217/'\n",
    "SFM_DIR = '/datasets/hsc/repo/rerun/RC/w_2020_03/DM-23121-sfm/'\n",
    "STK_DIR = '/datasets/hsc/repo/rerun/RC/w_2020_03/DM-23121/'\n",
    "butler = dafPersist.Butler(STK_DIR)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.86 ms\n"
     ]
    }
   ],
   "source": [
    "from comparisonHelpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate single visit \"database\"\n",
    " * File 00a_dbselect.dat is a partial dump from the IPP HSC processing database in Hawaii.\n",
    " * The output database matches this dump to the gen2 HSC registry, and extracts pointing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.42 ms\n"
     ]
    }
   ],
   "source": [
    "def makeDatabase():\n",
    "    db = pd.read_csv(PROJ_DIR + \"hsc_rc2.20200214/00a_dbselect.dat\", sep='\\t', header=0)\n",
    "    db = db[db['state'] == 'full']\n",
    "    db['visit'] = [x.split('-')[1] for x in db['exp_name']]\n",
    "    db['IPPSMF'] = [glob.glob(PROJ_DIR + dg + \"/\" + expN + \".\" + str(expI) + '/*.smf')\n",
    "                    for dg, expN, expI in \n",
    "                    zip(db['data_group'], db['exp_name'], db['exp_id'])]\n",
    "    db['IPPSMF'] = [x[0] if len(x) else None for x in db['IPPSMF']]\n",
    "\n",
    "    conn = sqlite3.connect(\"/datasets/hsc/repo/registry.sqlite3\")\n",
    "    c = conn.cursor()\n",
    "    pointings = []\n",
    "    for visit in db['visit']:\n",
    "        c.execute(f'SELECT DISTINCT pointing, visit FROM raw WHERE visit={int(visit)}')\n",
    "        (p, outVis) = c.fetchone()\n",
    "        pointings.append(p)\n",
    "    db['pointing'] = pointings\n",
    "    conn.close()\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map a common name to the catalog names for both catalog types:\n",
    " * commonName -> (ippName, drpName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.07 ms\n"
     ]
    }
   ],
   "source": [
    "TRANSLATOR = {'id': ('IPP_IDET', 'id'),\n",
    "              'x': ('X_PSF', 'base_SdssCentroid_x'), 'y': ('Y_PSF', 'base_SdssCentroid_y'),\n",
    "              'ra': ('RA_PSF', 'coord_ra'), 'dec': ('DEC_PSF', 'coord_dec'),\n",
    "              'psfFlux': ('PSF_INST_FLUX', 'base_PsfFlux_instFlux'),\n",
    "              'psfFluxSig': ('PSF_INST_FLUX_SIG', 'base_PsfFlux_instFluxErr'),\n",
    "              'apCorr': ('AP_FLUX', 'base_PsfFlux_apCorr'),\n",
    "              'apCorrSig': ('AP_FLUX_SIG', 'base_PsfFlux_apCorrErr'),\n",
    "              'sky': ('SKY', 'base_LocalBackground_instFlux'), \n",
    "              'skySig': ('SKY_SIGMA', 'base_LocalBackground_instFluxErr'),\n",
    "              'nExtSig': ('EXT_NSIGMA', 'base_ClassificationExtendedness_value'),\n",
    "              'PSF_MAJOR': ('PSF_MAJOR', 'base_SdssShape_psf_xx'),\n",
    "              'PSF_MINOR': ('PSF_MINOR', 'base_SdssShape_psf_yy'),\n",
    "              'PSF_THETA': ('PSF_THETA', 'base_SdssShape_psf_xy'),\n",
    "              'KRON_FLUX': ('KRON_FLUX', 'ext_photometryKron_KronFlux_instFlux'),\n",
    "              'KRON_FLUX_ERR': ('KRON_FLUX_ERR', 'ext_photometryKron_KronFlux_instFluxErr'),\n",
    "              'Mxx': ('MOMENTS_XX', 'base_SdssShape_xx'),\n",
    "              'Mxy': ('MOMENTS_XY', 'base_SdssShape_xy'),\n",
    "              'Myy': ('MOMENTS_YY', 'base_SdssShape_yy'),\n",
    "              'flags': ('FLAGS', 'deblend_nChild'),\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple matching algorithm assuming sorted input tables.  Not as fast as I had hoped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.5 ms\n"
     ]
    }
   ],
   "source": [
    "def finalMatch(tableA, tableB, radius=3.0):\n",
    "    matched = []\n",
    "\n",
    "    for ai, aa in enumerate(tableA):\n",
    "        R = radius**2\n",
    "        bestMatch = None\n",
    "        bestIndex = None\n",
    "        # print(aa)\n",
    "\n",
    "        start = np.searchsorted(tableB['X'], aa['X'] - radius)\n",
    "        stop = np.searchsorted(tableB['X'], aa['X'] + radius)\n",
    "        for bi, bb in enumerate(tableB[start:stop], start=start):\n",
    "            rr = (aa['X'] - bb['X'])**2 + (aa['Y'] - bb['Y'])**2\n",
    "            if rr < R:\n",
    "                bestMatch = bb\n",
    "                bestIndex = bi\n",
    "                R = rr\n",
    "        if bestMatch is not None:\n",
    "            matched.append((ai, bestIndex, np.sqrt(R)))\n",
    "\n",
    "    ippIDs = np.array([int(ii[0]) for ii in matched])\n",
    "    drpIDs = np.array([int(ii[1]) for ii in matched])\n",
    "    RR = np.array([ii[2] for ii in matched])\n",
    "\n",
    "    ippChip = {TRANSLATOR[k][0]: tableA[TRANSLATOR[k][0]][ippIDs] for k in TRANSLATOR.keys()}\n",
    "    drpChip = {TRANSLATOR[k][1]: tableB[TRANSLATOR[k][1]][drpIDs] for k in TRANSLATOR.keys()}\n",
    "    DF = pd.DataFrame(data={'matchRadius': RR, # 'chip': chipName,\n",
    "                            'ippID': ippIDs, 'drpID': drpIDs,\n",
    "                            'X_IPP': tableA['X'][ippIDs], 'Y_IPP': tableA['Y'][ippIDs],\n",
    "                            'X_DRP': tableB['X'][drpIDs], 'Y_DRP': tableB['Y'][drpIDs],\n",
    "                            **ippChip, **drpChip})\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over database rows and:\n",
    " * Read IPP SMF catalog for that exposure\n",
    " * Iterate over SMF extensions for each chip\n",
    " * Get 'src' product from butler for the associated DRP result\n",
    " * Add instrumental magnitudes\n",
    " * Add common x-orientation column\n",
    " * Match catalogs together\n",
    " * Write per-chip matched, solo results for TRANSLATOR columns\n",
    " * Write per-exposure matched catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not excecuting cell to prevent over-write of data.\n",
      "time: 11.8 ms\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert(False)\n",
    "except:\n",
    "    print(\"Not excecuting cell to prevent over-write of data.\")\n",
    "else:\n",
    "    for idx, row in db.iterrows():\n",
    "        print(idx, row)\n",
    "        smf = row['IPPSMF']\n",
    "        visitId = row['visit']\n",
    "        print(smf)\n",
    "        Fsmf = FF.open(smf)\n",
    "        DF = []\n",
    "\n",
    "        for ext_number, hdu in enumerate(Fsmf, start=0):\n",
    "            ext_name = hdu.header.get('EXTNAME', 'PRIMARY')\n",
    "            if '.psf' not in ext_name:\n",
    "                continue\n",
    "            chipName = ext_name.replace('.psf', \"\").replace('x', \"\")\n",
    "            print(f\"{visitId} {chipName} {smf}\")\n",
    "            ippTable = QTable(hdu.data)\n",
    "            ippTable['PSF_INST_MAG'] = -2.5 * np.log10(ippTable['PSF_INST_FLUX'])\n",
    "            ippTable.sort(['X_PSF', 'Y_PSF', 'PSF_INST_MAG'])\n",
    "            ippTable['X'] = 2048.0 - ippTable['X_PSF']\n",
    "            ippTable['Y'] = ippTable['Y_PSF']\n",
    "            ippTable.sort(['X', 'Y', 'PSF_INST_MAG'])\n",
    "\n",
    "            drpTable = None\n",
    "            try:\n",
    "                drpTable = butler.get('src', dataId={'visit': int(visitId), 'ccd': int(chipName)})\n",
    "            except dafPersist.NoResults:\n",
    "                continue\n",
    "            drpTable = QTable(drpTable.asAstropy())\n",
    "            drpTable['base_PsfFlux_instMag'] = -2.5 * np.log10(drpTable['base_PsfFlux_instFlux'] /u.ct)\n",
    "            drpTable.sort(['base_SdssCentroid_x', 'base_SdssCentroid_y'])\n",
    "            drpTable['X'] = drpTable['base_SdssCentroid_x'] / u.pix\n",
    "            drpTable['Y'] = drpTable['base_SdssCentroid_y'] / u.pix\n",
    "            drpTable.sort(['X', 'Y'])\n",
    "\n",
    "            matched = finalMatch(ippTable, drpTable, radius=5.0)\n",
    "            matched['chip'] = chipName\n",
    "\n",
    "            ippTable = ippTable.to_pandas()\n",
    "            drpTable = drpTable.to_pandas()\n",
    "\n",
    "            ippSolo = ippTable[~ippTable.IPP_IDET.isin(matched['IPP_IDET'])]\n",
    "            drpSolo = drpTable[~drpTable.id.isin(matched['id'])]\n",
    "\n",
    "            matched.to_parquet(PROJ_DIR + f\"matched_chip/v{visitId}-{chipName}.pqt\")\n",
    "\n",
    "            ippSolo.to_csv(PROJ_DIR + f\"soloIPP/v{visitId}-{chipName}.pqt\")\n",
    "            drpSolo.to_csv(PROJ_DIR + f\"soloDRP/v{visitId}-{chipName}.pqt\")\n",
    "\n",
    "            DF.append(matched)\n",
    "\n",
    "        outDF = pd.concat(DF)\n",
    "        outDF.to_parquet(PROJ_DIR + f\"matched/v{visitId}.pqt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate summary statistics of parameter differences\n",
    " * Loop over database rows and known chips\n",
    " * Reread matched chip catalogs\n",
    " * Create differences of RA, DEC, PSF Instrumental Mag, and Kron Instrumental Mag\n",
    " * Calculate percentiles of each\n",
    " * Write statistics with (exposure, chip, filter) keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not executing cell to prevent over-write of data.\n",
      "time: 10.2 ms\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert(False)\n",
    "except:\n",
    "    print(\"Not executing cell to prevent over-write of data.\")\n",
    "else:\n",
    "    def stat(vectorLike):\n",
    "        return np.nanpercentile(vectorLike, [0, 25, 50, 75, 100])\n",
    "\n",
    "    def chipStats(df):\n",
    "        # astrometry:\n",
    "        r2d = 180.0 / np.pi\n",
    "        dR = stat(df['RA_PSF'] - df['coord_ra'] * r2d)\n",
    "        dD = stat(df['DEC_PSF'] - df['coord_dec'] * r2d)\n",
    "        # photometry\n",
    "        dM = stat(np.log10(df['PSF_INST_FLUX']) - np.log10(df['base_PsfFlux_instFlux']))\n",
    "        dKM = stat(np.log10(df['KRON_FLUX']) -  np.log10(df['ext_photometryKron_KronFlux_instFlux']))\n",
    "        return [dR, dD, dM, dKM]\n",
    "\n",
    "    chips = range(104)\n",
    "\n",
    "    visits = []\n",
    "    filters = []\n",
    "    chipCol = []\n",
    "    dR = {}\n",
    "    dD = {}\n",
    "    dM = {}\n",
    "    dK = {}\n",
    "    for Q in (0, 25, 50, 75, 100):\n",
    "        dR[Q] = []\n",
    "        dD[Q] = []\n",
    "        dM[Q] = []\n",
    "        dK[Q] = []\n",
    "\n",
    "    for idx, row in db.iterrows():\n",
    "    #    print(row)\n",
    "        visitId = row['visit']\n",
    "        filter = row['filter']\n",
    "        for chip in chips:\n",
    "            try:\n",
    "                match = pq2df(PROJ_DIR + f\"try1/matched_chip/v{visitId:07d}-{chip:03d}.pqt\")\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            #        print(chip)\n",
    "            R = chipStats(match)\n",
    "            if isinstance(R[0], np.float):\n",
    "                continue\n",
    "            if len(R[0]) > 0:\n",
    "                visits.append(visitId)\n",
    "                filters.append(filter)\n",
    "                chipCol.append(chip)\n",
    "                for ii, Q in enumerate((0, 25, 50, 75, 100)):\n",
    "                    dR[Q].append(R[0][ii])\n",
    "                    dD[Q].append(R[1][ii])\n",
    "                    dM[Q].append(R[2][ii])\n",
    "                    dK[Q].append(R[3][ii])\n",
    "            print(visitId, chip ,filter)\n",
    "    SS = pd.DataFrame({'visit': visits, 'filter': filters, 'chip': chipCol,\n",
    "                       'dR00': dR[0], 'dR25': dR[25], 'dR50': dR[50],\n",
    "                       'dR75': dR[75], 'dR100': dR[100],\n",
    "                       'dD00': dD[0], 'dD25': dD[25], 'dD50': dD[50],\n",
    "                       'dD75': dD[75], 'dD100': dD[100],\n",
    "                       'dM00': dM[0], 'dM25': dM[25], 'dM50': dM[50],\n",
    "                       'dM75': dM[75], 'dM100': dM[100],\n",
    "                       'dK00': dK[0], 'dK25': dK[25], 'dK50': dK[50],\n",
    "                       'dK75': dK[75], 'dK100': dK[100],\n",
    "                      })\n",
    "    SS.to_parquet(PROJ_DIR + \"sfm_ss.pqt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be lazy instead of smart.\n",
    " * Iterate over tracts, patches, and filters\n",
    " * Extract bbox and wcs\n",
    " * Find extents for all existing DRP coadds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not executing cell to prevent over-write of data.\n",
      "time: 8.74 ms\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert(False)\n",
    "except:\n",
    "    print(\"Not executing cell to prevent over-write of data.\")\n",
    "else:\n",
    "    def makeDRPdb():\n",
    "        filters = ['HSC-G', 'HSC-R', 'HSC-I', 'HSC-Z', 'HSC-Y', 'NB0921']\n",
    "        tracts = [9615, 9697, 9813]\n",
    "        patches = []\n",
    "    \n",
    "        TT = []\n",
    "        PP = []\n",
    "        FF = []\n",
    "        RRm = []\n",
    "        RRM = []\n",
    "        DDm = []\n",
    "        DDM = []\n",
    "        for u in range(8):\n",
    "            for v in range(8):\n",
    "                pp = f\"{u},{v}\"\n",
    "                patches.append(pp)\n",
    "        for T in tracts:\n",
    "            for F in filters:\n",
    "                for P in patches:\n",
    "                    rMin = 99e99\n",
    "                    rMax = -99e99\n",
    "                    dMin = 99e99\n",
    "                    dMax = -99e99\n",
    "                    try:\n",
    "                        ss = butler.get(\"deepCoadd\", {'tract': T, 'patch': P, 'filter': F})\n",
    "                    except:\n",
    "                        continue\n",
    "                    wcs = ss.getWcs()\n",
    "                    bb = ss.getBBox().getCorners()\n",
    "                    for c in bb:\n",
    "                        rd = wcs.pixelToSky(c[0], c[1])\n",
    "                    \n",
    "                        if rd[0].asDegrees() < rMin:\n",
    "                            rMin = rd[0].asDegrees()\n",
    "                        elif rd[0].asDegrees() > rMax:\n",
    "                            rMax = rd[0].asDegrees()\n",
    "                        if rd[1].asDegrees() < dMin:\n",
    "                            dMin = rd[1].asDegrees()\n",
    "                        elif rd[1].asDegrees() > dMax:\n",
    "                            dMax = rd[1].asDegrees()\n",
    "                    TT.append(T)\n",
    "                    PP.append(P)\n",
    "                    FF.append(F)\n",
    "                    RRm.append(rMin)\n",
    "                    RRM.append(rMax)\n",
    "                    DDm.append(dMin)\n",
    "                    DDM.append(dMax)\n",
    "        DF = pd.DataFrame({'tract': TT, 'patch': PP, 'filter': FF,\n",
    "                           'RAmin': RRm, 'RAmax': RRM,\n",
    "                          'DECmin': DDm, 'DECmax': DDM})\n",
    "        return(DF)\n",
    "    \n",
    "    drpSdb = makeDRPdb()\n",
    "    drpSdb.to_parquet(PROJ_DIR + \"/drpSdb.pqt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read IPP coadd database dump containing fields used in filenames.\n",
    " * As well as filter and extent information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stack_id</th>\n",
       "      <th>filter</th>\n",
       "      <th>state</th>\n",
       "      <th>data_group</th>\n",
       "      <th>count(warp_id)</th>\n",
       "      <th>sum(good_frac)</th>\n",
       "      <th>skycell_id</th>\n",
       "      <th>radeg</th>\n",
       "      <th>decdeg</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4906</td>\n",
       "      <td>HSC-g</td>\n",
       "      <td>full</td>\n",
       "      <td>czwRC2.wide.20200220</td>\n",
       "      <td>5</td>\n",
       "      <td>3.264171</td>\n",
       "      <td>skycell.1286.348</td>\n",
       "      <td>216.300</td>\n",
       "      <td>-0.499357</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4907</td>\n",
       "      <td>HSC-g</td>\n",
       "      <td>full</td>\n",
       "      <td>czwRC2.wide.20200220</td>\n",
       "      <td>6</td>\n",
       "      <td>3.387012</td>\n",
       "      <td>skycell.1286.364</td>\n",
       "      <td>217.099</td>\n",
       "      <td>-0.299340</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4908</td>\n",
       "      <td>HSC-g</td>\n",
       "      <td>full</td>\n",
       "      <td>czwRC2.wide.20200220</td>\n",
       "      <td>6</td>\n",
       "      <td>4.387497</td>\n",
       "      <td>skycell.1286.365</td>\n",
       "      <td>216.900</td>\n",
       "      <td>-0.299359</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4909</td>\n",
       "      <td>HSC-g</td>\n",
       "      <td>full</td>\n",
       "      <td>czwRC2.wide.20200220</td>\n",
       "      <td>6</td>\n",
       "      <td>3.437412</td>\n",
       "      <td>skycell.1286.366</td>\n",
       "      <td>216.700</td>\n",
       "      <td>-0.299373</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4910</td>\n",
       "      <td>HSC-g</td>\n",
       "      <td>full</td>\n",
       "      <td>czwRC2.wide.20200220</td>\n",
       "      <td>6</td>\n",
       "      <td>3.645687</td>\n",
       "      <td>skycell.1286.367</td>\n",
       "      <td>216.500</td>\n",
       "      <td>-0.299384</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stack_id filter state            data_group  count(warp_id)  \\\n",
       "0      4906  HSC-g  full  czwRC2.wide.20200220               5   \n",
       "1      4907  HSC-g  full  czwRC2.wide.20200220               6   \n",
       "2      4908  HSC-g  full  czwRC2.wide.20200220               6   \n",
       "3      4909  HSC-g  full  czwRC2.wide.20200220               6   \n",
       "4      4910  HSC-g  full  czwRC2.wide.20200220               6   \n",
       "\n",
       "   sum(good_frac)        skycell_id    radeg    decdeg     width    height  \n",
       "0        3.264171  skycell.1286.348  216.300 -0.499357  0.208333  0.208458  \n",
       "1        3.387012  skycell.1286.364  217.099 -0.299340  0.208333  0.208458  \n",
       "2        4.387497  skycell.1286.365  216.900 -0.299359  0.208333  0.208458  \n",
       "3        3.437412  skycell.1286.366  216.700 -0.299373  0.208333  0.208458  \n",
       "4        3.645687  skycell.1286.367  216.500 -0.299384  0.208333  0.208458  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 43.3 ms\n"
     ]
    }
   ],
   "source": [
    "db = pq2df(PROJ_DIR + 'hsc_rc2.20200214/02a_dbselect.dat', sep='\\t')\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper function to find IPP coadd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.55 ms\n"
     ]
    }
   ],
   "source": [
    "def rd2ims(ra, dec, filter):\n",
    "    row = db[db['filter' == filter] & \n",
    "             db['radeg' - 'width' / 2.0 <= ra] &\n",
    "             db['radeg' + 'width' / 2.0 >= ra] &\n",
    "             db['decdeg' - 'height' / 2.0 <= dec] &\n",
    "             db['decdeg' + 'height' / 2.0 >= dec] ]\n",
    "    for r in row:\n",
    "        ippStack = (PROJ_DIR + f\"/{r['data_group']}/HSC.V0/{r['skycell_id']}/\" +\n",
    "                     f\"HSC.V0.{r['skycell_id']}.stk.{r['stack_id']}.unconv.fits\")\n",
    "        return ippStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
